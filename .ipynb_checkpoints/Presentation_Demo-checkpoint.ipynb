{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ad23d0",
   "metadata": {},
   "source": [
    "# BirdID\n",
    "#### Project #1\n",
    "#### 4152 Computer Vision - Course Project - Micah Thomas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ed10f6",
   "metadata": {},
   "source": [
    "![BirdGif1](demo_assets/one.gif \"one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ded9d5",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ee9c47",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "**BirdID is a machine learning project used to predict the species of local birds in my backyard.**\n",
    "\n",
    "Team Members: Micah Thomas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad769f65",
   "metadata": {},
   "source": [
    "# Problem & Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f8dac6",
   "metadata": {},
   "source": [
    "Motivation:\n",
    "* What are all these birds in my backyard?\n",
    "\n",
    "Goals:\n",
    "* Build a bird feeder and collect data of birds\n",
    "* Train a ML model to accurately label bird species\n",
    "* Predict bird species in real time\n",
    "\n",
    "I began the project by first searching for datasets online:\n",
    "* The Cornell Lab of Ornithology offers a free-to-use North America bird dataset, featuring 400 bird species and 48,000 photos with labels.\n",
    "* The California Institute of Technology offers a free-to-use *mainly* North America bird dataset, featuring 200 species and 6,033 images with bounding boxes and labels.\n",
    "\n",
    "However, only 8 winter birds in my backyard:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f279e8a",
   "metadata": {},
   "source": [
    "### Blue Jay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a20cbe",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/blue_jay.png\" alt=\"Blue Jay\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba8188",
   "metadata": {},
   "source": [
    "### Brown-headed Nuthatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47bbaa7",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/brown_headed_nuthatch.jpg\" alt=\"Brown-headed Nuthatch\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a2fb29",
   "metadata": {},
   "source": [
    "### Cardinal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea48606e",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/cardinal.jpg\" alt=\"Cardinal\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8acff8",
   "metadata": {},
   "source": [
    "### Carolina Chickadee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36642ef2",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/carolina_chickadee.jpg\" alt=\"Carolina Chickadee\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f4ba2f",
   "metadata": {},
   "source": [
    "### Carolina Wren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0621690",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/carolina_wren.jpg\" alt=\"Carolina Wren\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377f4ed2",
   "metadata": {},
   "source": [
    "### Downy Woodpecker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd65abd",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/downy_woodpecker.jpg\" alt=\"Downy Woodpecker\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fad8e66",
   "metadata": {},
   "source": [
    "### Red-bellied Woodpecker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6671afe",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/red_bellied_woodpecker.jpg\" alt=\"Red Bellied Woodpecker\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2875acd",
   "metadata": {},
   "source": [
    "### Tufted Titmouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb91150a",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/tufted_titmouse.jpg\" alt=\"Tufted Titmouse\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dc3060",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035fc778",
   "metadata": {},
   "source": [
    "Problem with datasets:\n",
    "* There are only 8 observed birds in my area.\n",
    "* Caltech and Cornell datasets are too broad, not enough diversity of images.\n",
    "* Assuming a model that purely predicts classes randomly (i.e. no learning), the probability of guessing a bird correctly from 400 species is 0.25%, while the probability of guessing a bird correctly from 8 species is 12.5%.\n",
    "\n",
    "Solution:\n",
    "* Collect all data myself.\n",
    "* Create an environment that will attract birds & take photos of them consistently.\n",
    "\n",
    "With this intuition, I decided to build a bird feeder and mount a camera that is always streaming to my computer. The goal now was to create an algorithm that would detect objects (the object hopefully being a bird) and then save continous captures of that object to my local computer. I would then use those images to train a convolutionary neural network using FastAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acdc1fc",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4fd7c5",
   "metadata": {},
   "source": [
    "### Building the bird feeder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d03b8b",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/bird_feeder.gif\" alt=\"Bird Feeder\" width=\"600\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e348c8",
   "metadata": {},
   "source": [
    "* Simple platform bird feeder bought from a store.\n",
    "* Animation shows modifications.\n",
    "* Waterproof box was mounted to the back with a webcam inside of it.\n",
    "* 180ft cable runs from webcam to my computer.\n",
    "\n",
    "Notes:\n",
    "* USB 2.0 can only travel 16ft.\n",
    "* USB 3.0 can only travel 10ft.\n",
    "* USB over Cat6 ethernet can travel up to 200ft."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab30a65",
   "metadata": {},
   "source": [
    "<table>\n",
    "   <tr>\n",
    "      <td><img src=\"demo_assets/side_view_feeder.jpg\" alt=\"Side View Bird Feeder\" width=\"600\"/></td>\n",
    "      <td><img src=\"demo_assets/feeder_angle_back_view.jpg\" alt=\"Back Angle View Bird Feeder\" width=\"600\"/></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f15cc87",
   "metadata": {},
   "source": [
    "It's not the prettiest bird feeder, but the birds don't seem to mind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8fa43e",
   "metadata": {},
   "source": [
    "### Capturing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed1c7b",
   "metadata": {},
   "source": [
    "* White board behind the feeder is used for consistent object detection.\n",
    "* Object detection algorithm compares the current frame of the webcam to the first frame- this 'difference' frame is used to detect objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87805f35",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/diff_thresh_still.png\" alt=\"Difference and Thresholding - Still\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4decf16a",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/diff_thresh.gif\" alt=\"Difference and Thresholding - GIF\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e76847b",
   "metadata": {},
   "source": [
    "* On the upper left you see the raw footage, granted with some bounding boxes overlaid but that is actually drawn later.\n",
    "\n",
    "* On the upper right you see the grayscale footage, which is then, for lack of better words, subtracted from the first frame in grayscale.\n",
    "\n",
    "* The difference is displayed in the lower left and you can see for the most part is just looks like the ghost of a bird on a black background.\n",
    "\n",
    "* On the lower right you see the threshold frame, which is made from the difference frame and simply makes pixels above a certain threshold value pure white and everything else pure black."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37b0bd5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf2d4b",
   "metadata": {},
   "source": [
    "* OpenCV provides methods to apply contour filtering.\n",
    "* Contours are mathematically different than edges, but you can think of them as such.\n",
    "    * Edges have no identity, contours do.\n",
    "* When a certain amount of contours are found from the threshold frame, a bounding box is drawn that represents the max width and height of the contours.\n",
    "* The white board prevents bad data captures from shadows and the bird feeder swinging on the cable.\n",
    "* After 10 days, I collected 60,000 images of birds, of which I used about 20,000 of."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01f98c5",
   "metadata": {},
   "source": [
    "### Verifying the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "757776a7",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "path = Path(os.getcwd())\n",
    "\n",
    "train_df = pd.read_csv(path/\"train_df.csv\")\n",
    "test_df = pd.read_csv(path/\"test_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f25afb",
   "metadata": {},
   "source": [
    "* 8 classes.\n",
    "* **20,398** usable images.\n",
    "* Manually labeled all of the photos.\n",
    "* Images from the Caltech and Cornell datasets were also merged. This added +60 images per class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819a048e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b76d1b3",
   "metadata": {},
   "source": [
    "* Create a Pandas dataframe from the collected data.\n",
    "* Each row is a data sample (photo).\n",
    "* The column `fname` is the name of the photo, which happens to be the time the photo was captured.\n",
    "* The column `rpath` is the relative path of where the photo is located.\n",
    "* The column `label` is the photo's corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c01d813c",
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>fpath</th>\n",
       "      <th>rpath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-07--10-28-16-767.jpg</td>\n",
       "      <td>Blue Jay</td>\n",
       "      <td>C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-07--10-28-16-767.jpg</td>\n",
       "      <td>Blue Jay/2021-11-07--10-28-16-767.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-07--10-28-17-311.jpg</td>\n",
       "      <td>Blue Jay</td>\n",
       "      <td>C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-07--10-28-17-311.jpg</td>\n",
       "      <td>Blue Jay/2021-11-07--10-28-17-311.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-08--11-58-29-841.jpg</td>\n",
       "      <td>Blue Jay</td>\n",
       "      <td>C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-08--11-58-29-841.jpg</td>\n",
       "      <td>Blue Jay/2021-11-08--11-58-29-841.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-08--11-58-30-925.jpg</td>\n",
       "      <td>Blue Jay</td>\n",
       "      <td>C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-08--11-58-30-925.jpg</td>\n",
       "      <td>Blue Jay/2021-11-08--11-58-30-925.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-08--11-58-31-465.jpg</td>\n",
       "      <td>Blue Jay</td>\n",
       "      <td>C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-08--11-58-31-465.jpg</td>\n",
       "      <td>Blue Jay/2021-11-08--11-58-31-465.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          fname     label  \\\n",
       "0  2021-11-07--10-28-16-767.jpg  Blue Jay   \n",
       "1  2021-11-07--10-28-17-311.jpg  Blue Jay   \n",
       "2  2021-11-08--11-58-29-841.jpg  Blue Jay   \n",
       "3  2021-11-08--11-58-30-925.jpg  Blue Jay   \n",
       "4  2021-11-08--11-58-31-465.jpg  Blue Jay   \n",
       "\n",
       "                                                                                  fpath  \\\n",
       "0  C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-07--10-28-16-767.jpg   \n",
       "1  C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-07--10-28-17-311.jpg   \n",
       "2  C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-08--11-58-29-841.jpg   \n",
       "3  C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-08--11-58-30-925.jpg   \n",
       "4  C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-08--11-58-31-465.jpg   \n",
       "\n",
       "                                   rpath  \n",
       "0  Blue Jay/2021-11-07--10-28-16-767.jpg  \n",
       "1  Blue Jay/2021-11-07--10-28-17-311.jpg  \n",
       "2  Blue Jay/2021-11-08--11-58-29-841.jpg  \n",
       "3  Blue Jay/2021-11-08--11-58-30-925.jpg  \n",
       "4  Blue Jay/2021-11-08--11-58-31-465.jpg  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5745b9f0",
   "metadata": {},
   "source": [
    "**Class Distributions**\n",
    "\n",
    "| Index | Class                  | Count |\n",
    "|-------|------------------------|-------|\n",
    "| 0     | Blue Jay               | 92    |\n",
    "| 1     | Brown-headed Nuthatch  | 353   |\n",
    "| 2     | Cardinal               | 2519  |\n",
    "| 3     | Carolina Chickadee     | 14675 |\n",
    "| 4     | Carolina Wren          | 625   |\n",
    "| 5     | Downy Woodpecker       | 221   |\n",
    "| 6     | Red-bellied Woodpecker | 86    |\n",
    "| 7     | Tufted Titmouse        | 1827  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd703c31",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50abc423",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/class_distrubutions.png\" alt=\"Class Distributions\" width=\"600\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c788fd6",
   "metadata": {},
   "source": [
    "As you can see, the dataset is highly imbalanced.\n",
    "\n",
    "* **Blue Jay** accounts for **0.017%** of the total images.\n",
    "* **Brown-headed Nuthatch** accounts for **1.487%** of the total images.\n",
    "* **Cardinal** accounts for **12.499%** of the total images.\n",
    "* **Carolina Chickadee** accounts for **74.155%** of the total images.\n",
    "* **Carolina Wren** accounts for **2.702%** of the total images.\n",
    "* **Downy Woodpecker** accounts for **0.509%** of the total images.\n",
    "* **Tufted Titmouse** accounts for **8.632%** of the total images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3f59f6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a43e4",
   "metadata": {},
   "source": [
    "* Imbalanced datasets lead to bad performance more similar to guessing.\n",
    "* The dataset will need to be over and under sampled, but first it needs to be split into train and test sets.\n",
    "* The validation set will be created from FastAI itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc2362",
   "metadata": {},
   "source": [
    "### Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4355440",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "def test_train_split(df, test_split_percent, label_helper):\n",
    "    frames = []\n",
    "    for i in range(len(label_helper)):\n",
    "        frames.append(df.groupby(['label']).get_group(label_helper[i][0]).reset_index())\n",
    "    test_frames = []\n",
    "    train_frames = []\n",
    "    for i in range(len(frames)):\n",
    "        dff = frames[i]\n",
    "        x = math.floor(dff.shape[0] * test_split_percent)\n",
    "        indices = np.random.choice(dff.index, x, replace=False)\n",
    "        test_frames.append(dff.iloc[indices].reset_index().drop(['level_0', 'index'], axis=1))\n",
    "        train_frames.append(dff.drop(indices).reset_index().drop(['level_0', 'index'], axis=1))\n",
    "    test_df = pd.concat(test_frames)\n",
    "    train_df = pd.concat(train_frames)\n",
    "    return test_df, train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a504041",
   "metadata": {},
   "source": [
    "* A function to split the dataset.\n",
    "* Argument `test_split_percent` will randomly choose that percentage of images from each class and move them to a separate dataset.\n",
    "* I chose 0.2, meaning 20 percent of each class will become the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ce3a826",
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>fpath</th>\n",
       "      <th>rpath</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blue Jay</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brown-headed Nuthatch</th>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardinal</th>\n",
       "      <td>503</td>\n",
       "      <td>503</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carolina Chickadee</th>\n",
       "      <td>2935</td>\n",
       "      <td>2935</td>\n",
       "      <td>2935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carolina Wren</th>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Downy Woodpecker</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red-bellied Woodpecker</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tufted Titmouse</th>\n",
       "      <td>365</td>\n",
       "      <td>365</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fname  fpath  rpath\n",
       "label                                      \n",
       "Blue Jay                   18     18     18\n",
       "Brown-headed Nuthatch      70     70     70\n",
       "Cardinal                  503    503    503\n",
       "Carolina Chickadee       2935   2935   2935\n",
       "Carolina Wren             131    131    131\n",
       "Downy Woodpecker           44     44     44\n",
       "Red-bellied Woodpecker     17     17     17\n",
       "Tufted Titmouse           365    365    365"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby(['label']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabfe4c4",
   "metadata": {},
   "source": [
    "Above is the test set, notice that there is still a data imbalance here but unlike in the training set, this is perfectly acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b3d450",
   "metadata": {},
   "source": [
    "### Over & Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "388d2cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "## Deletes 'remove_n' random rows\n",
    "def undersample(df, count, target):\n",
    "    remove_n = count - target\n",
    "    drop_indices = np.random.choice(df.index, remove_n, replace=False)\n",
    "    df_subset = df.drop(drop_indices)\n",
    "    return df_subset\n",
    "\n",
    "## Duplicates 'duplicate_n' random rows\n",
    "def oversample(df, count, target):\n",
    "    duplicate_n = math.ceil(target / count)\n",
    "    df_over = pd.concat([df]*duplicate_n)\n",
    "    over_count = df_over.shape[0]\n",
    "    if over_count > target:\n",
    "        remove_n = over_count - target\n",
    "        df_over = df_over.iloc[:-remove_n]\n",
    "    return df_over\n",
    "\n",
    "def over_under_sample(df, target, labels):\n",
    "    frames = []\n",
    "    for i, label in enumerate(labels):\n",
    "        dff = df[df.label == labels[i]].reset_index()\n",
    "        dff_count = dff.shape[0]\n",
    "        if dff_count > target:\n",
    "            dff = undersample(dff, dff_count, target)\n",
    "        elif dff_count < target:\n",
    "            dff = oversample(dff, dff_count, target)\n",
    "        dff.reset_index()\n",
    "        frames.append(dff)\n",
    "    balanced_df = pd.concat(frames)\n",
    "    return balanced_df.reset_index().drop(['level_0', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8178da7",
   "metadata": {},
   "source": [
    "* A function to balance the dataset.\n",
    "* Argument `target` will either oversample (randomly duplicate images) or undersample (randomly delete images) until each class has the exact same amount of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a7d8740",
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>fpath</th>\n",
       "      <th>rpath</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blue Jay</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brown-headed Nuthatch</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardinal</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carolina Chickadee</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carolina Wren</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Downy Woodpecker</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red-bellied Woodpecker</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tufted Titmouse</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fname  fpath  rpath\n",
       "label                                      \n",
       "Blue Jay                 1000   1000   1000\n",
       "Brown-headed Nuthatch    1000   1000   1000\n",
       "Cardinal                 1000   1000   1000\n",
       "Carolina Chickadee       1000   1000   1000\n",
       "Carolina Wren            1000   1000   1000\n",
       "Downy Woodpecker         1000   1000   1000\n",
       "Red-bellied Woodpecker   1000   1000   1000\n",
       "Tufted Titmouse          1000   1000   1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(['label']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435c9335",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/over_under_sample.png\" alt=\"Over Under Sample\" width=\"600\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b288afd2",
   "metadata": {},
   "source": [
    "* The dataset is now balanced.\n",
    "* Each class has 1000 samples.\n",
    "\n",
    "The class `Carolina Chickadee` was undersampled, so over 13,000 images are not being used but the 1000 images that are being used are entirely unique. \n",
    "\n",
    "The class `Blue Jay` was oversampled. It only had 92 images to begin with and we pretty much duplicated images until there were 1000, so 908 images are not unique. If we trained the model with this, it could become overfit, so the solution is to do some data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c37f4b",
   "metadata": {},
   "source": [
    "### Data Augmentation and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d809bd",
   "metadata": {},
   "source": [
    "Types of transformations applied:\n",
    "* +- Contrast\n",
    "* +- Saturation\n",
    "* +- Brightness\n",
    "* +- Zoom\n",
    "* +- Rotated\n",
    "* +- Warped\n",
    "\n",
    "After these transformations, there are no unique images in any class. Every image that the network trains off of is different, even if the difference is slight.\n",
    "\n",
    "Additionally, all images are reszed to 240px by 320px, which is half their original resolution of 480px by 640px. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75bd449",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/one_batch.png\" alt=\"One Batch\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce19f22",
   "metadata": {},
   "source": [
    "Here you can see some of these images are rotated and zoomed in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976b9d35",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fec926",
   "metadata": {},
   "source": [
    "* Important to use convolutional neural networks in this image classification task because they summarize all of the features seen in an image.\n",
    "* This is in contrast to a traditional fully connected layer where the location of a feature is the actual input to the model, here a feature is the input.\n",
    "* I trained 15 total models, but the model that performed best was an implementation of ResNet50, so I will focus on that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9ac4f1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b06f04",
   "metadata": {},
   "source": [
    "This problem was solved using FastAI 2 and a pretrained convolution model called **ResNet50**.\n",
    "\n",
    "ResNet50 has 48 convolution layers, 1 maxpool and 1 average pool layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aa40ae",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/resnet50.jpg\" alt=\"Resnet50 Architecture\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255a4975",
   "metadata": {},
   "source": [
    "> https://stackoverflow.com/questions/54943307/create-cnn-model-architecture-diagram-in-keras\n",
    "\n",
    "> Optimized Deep Convolutional Neural Networks for Identification of Macular Diseases from Optical Coherence Tomography Images - Scientific Figure on ResearchGate. Available from: https://www.researchgate.net/figure/Left-ResNet50-architecture-Blocks-with-dotted-line-represents-modules-that-might-be_fig3_331364877 [accessed 27 Nov, 2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3b7e79",
   "metadata": {},
   "source": [
    "**Architecture**  \n",
    "ResNet50\n",
    "\n",
    "**Parameters**  \n",
    "Total parameters: 21,816,128\n",
    "\n",
    "**Hyperparameters**  \n",
    "Learning rate is determined using FastAI's `learner.lr_find()` class method, which helps find the learning rate whose slope has the greatest negative value. On average, this value was `10E-4.5`.   `24` epochs over 4 training cycles.\n",
    "\n",
    "**Loss Function**  \n",
    "ResNet50 uses `FlattenedLoss of CrossEntropyLoss` as its loss function. Cross-entropy calculates the different between two probability distributions, which is the output of the model.\n",
    "\n",
    "**Performance Metric**  \n",
    "I chose `Error Rate` as my metric, which is really just `1 - Accuracy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61607821",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5ada2f",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709e7c12",
   "metadata": {},
   "source": [
    "4 distinct training cycles using FastAI's `fit_one_cycle` and `fine_tune`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e94bd2",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "##### Training Cycle 1\n",
    "\n",
    "**Epochs: `5`**  \n",
    "**Alpha: `10E-2.5`**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bf83bb",
   "metadata": {},
   "source": [
    "<table>\n",
    "   <tr>\n",
    "      <td><img src=\"demo_assets/lrfind_1.png\" alt=\"LR Find 1\" width=\"600\"/></td>\n",
    "      <td><img src=\"demo_assets/lrresult_1.png\" alt=\"LR Result 1\" width=\"600\"/></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5864dd9c",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/cm_1.png\" alt=\"Confusion Matrix 1\" width=\"400\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebf6970",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "##### Training Cycle 2\n",
    "\n",
    "**Epochs: `8`**  \n",
    "**Alpha: `10E-3`**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e9c384",
   "metadata": {},
   "source": [
    "<table>\n",
    "   <tr>\n",
    "      <td><img src=\"demo_assets/lrresult_2.png\" alt=\"LR Result 2\" width=\"600\"/></td>\n",
    "      <td><img src=\"demo_assets/cm_2.png\" alt=\"Confusion Matrix 2\" width=\"600\"/></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7874e07",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "##### Training Cycle 3\n",
    "\n",
    "**Epochs: `3`**  \n",
    "**Alpha: `10E-6`**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3074c7e2",
   "metadata": {},
   "source": [
    "<table>\n",
    "   <tr>\n",
    "      <td><img src=\"demo_assets/lrfind_3.png\" alt=\"LR Find 3\" width=\"600\"/></td>\n",
    "      <td><img src=\"demo_assets/lrres_3.png\" alt=\"LR Result 3\" width=\"600\"/></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7909991e",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/cmatrix_3.png\" alt=\"Confusion Matrix 3\" width=\"400\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a0399d",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "##### Training Cycle 4\n",
    "\n",
    "**Epochs: `6`**  \n",
    "**Alpha: `10E-6.15`**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f449267c",
   "metadata": {},
   "source": [
    "<table>\n",
    "   <tr>\n",
    "      <td><img src=\"demo_assets/lrfind_4.png\" alt=\"LR Find 4\" width=\"600\"/></td>\n",
    "      <td><img src=\"demo_assets/lrres_4.png\" alt=\"LR Result 4\" width=\"600\"/></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab188e8",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/cm_4.png\" alt=\"Confusion Matrix 4\" width=\"400\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aa2d20",
   "metadata": {},
   "source": [
    "As you can see, by the fourth training cyle we have a `train_loss` of 0.027 and a `valid_loss` of 0.023. On our first training cycle `train_loss` was 0.81 and `valid_loss` was 0.69."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0704d48",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6993e6e",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/final_report.png\" alt=\"Final Report\" width=\"800\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b98bd5",
   "metadata": {},
   "source": [
    "**Precision:** ratio `tp / (tp + fp)`\n",
    "\n",
    "**Recall:** ratio `tp (tp + fn)`\n",
    "\n",
    "**F1-score:** weighted mean of precision and recall, 1 is best, 0 is worst.\n",
    "\n",
    "As you can see from the report generated from FastAI, the model has great results from the train and valid set. It appears that the Tufted Titmouse is our worse performer, but it still performed very well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f154b3c",
   "metadata": {},
   "source": [
    "### Making Predictions with the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76903ae1",
   "metadata": {},
   "source": [
    "To make sure the model is not overfit and to evaluate its performance before making live predictions, we must test the model by making predictions on the test set.\n",
    "\n",
    "\n",
    "**Results:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3305d50d",
   "metadata": {},
   "source": [
    "**Accuracy**: 96.72  \n",
    "**Score**: 1915/1980  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1454ca76",
   "metadata": {},
   "source": [
    "Out of 1980 images the model has not yet seen, it predicted 1915 of them correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c070bdb",
   "metadata": {},
   "source": [
    "### Live Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b57b888",
   "metadata": {},
   "source": [
    "All of these photos/animations were taken using a prediction script, which is a variant of my capture script. When a object is detecting, instead of saving that photo to my computer, the script uses the ML model to make a prediction. The results of that prediction are displayed above the bird."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5c15b5",
   "metadata": {},
   "source": [
    "<table>\n",
    "   <tr>\n",
    "      <td><img src=\"demo_assets/pred2.png\" alt=\"Pred 2\" width=\"600\"/></td>\n",
    "      <td><img src=\"demo_assets/pred3.png\" alt=\"Pred 3\" width=\"600\"/></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0117a1",
   "metadata": {},
   "source": [
    "<table>\n",
    "   <tr>\n",
    "      <td><img src=\"demo_assets/pred4.png\" alt=\"Pred 4\" width=\"600\"/></td>\n",
    "      <td><img src=\"demo_assets/pred5.png\" alt=\"Pred 5\" width=\"600\"/></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bffec8d",
   "metadata": {},
   "source": [
    "<table>\n",
    "   <tr>\n",
    "      <td><img src=\"demo_assets/pred6.png\" alt=\"Pred 6\" width=\"600\"/></td>\n",
    "      <td><img src=\"demo_assets/pred7.png\" alt=\"Pred 7\" width=\"600\"/></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c534d760",
   "metadata": {},
   "source": [
    "<table>\n",
    "   <tr>\n",
    "      <td><img src=\"demo_assets/pred1.gif\" alt=\"Pred 1\" width=\"600\"/></td>\n",
    "      <td><img src=\"demo_assets/pred8.png\" alt=\"Pred 8\" width=\"600\"/></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bb97c0",
   "metadata": {},
   "source": [
    "*Squirrel problems*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5540b5",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/sqi.gif\" alt=\"Squirrel Trouble\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b30b80",
   "metadata": {},
   "source": [
    "*Model still works when white background is removed- success!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55a174d",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/sanity_check.gif\" alt=\"Sanity Check\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64ec985",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73862e21",
   "metadata": {},
   "source": [
    "To conclude, **BirdID** is a machine learning project used to predict the species of local birds in my backyard. The ML model was trained via transfer learning using the ResNet50 convolutional neural network with 8000 images of 8 local bird species collecting using object detection techniques.\n",
    "\n",
    "The model is set up to easily accommodate more classes as I collect more data.\n",
    "\n",
    "This was a difficult project, mainly because I chose to collect my own dataset, but I learned a lot about computer vision, machine learning, and birds in the process. I graduate in December and I plan to start working on BirdID version 2 in my free time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ca9e0c",
   "metadata": {},
   "source": [
    "# Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89d67a9",
   "metadata": {},
   "source": [
    "Any questions?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
