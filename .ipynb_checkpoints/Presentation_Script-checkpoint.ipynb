{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ad23d0",
   "metadata": {},
   "source": [
    "# BirdID\n",
    "#### Project #1\n",
    "#### 4152 Computer Vision - Course Project - Micah Thomas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ed10f6",
   "metadata": {},
   "source": [
    "![BirdGif1](demo_assets/one.gif \"one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ded9d5",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ee9c47",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "**BirdID is a machine learning project used to predict the species of local birds in my backyard.**\n",
    "\n",
    "Team Members: Micah Thomas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad769f65",
   "metadata": {},
   "source": [
    "# Problem & Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f8dac6",
   "metadata": {},
   "source": [
    "This past summer, as the coronavirus pandemic forced people to stay home, I became more interested in outdoor hobbies, especially gardening. While working in my garden, I began to notice many different species of birds that I have never paid attention to before.\n",
    "\n",
    "For my computer vision course project, I decided it would be a great chance to combine many of interests and build a ML model for bird species classification.\n",
    "\n",
    "Goals:\n",
    "* Build a bird feeder and collect data of birds\n",
    "* Train a ML model to accuractly label bird species\n",
    "* Predict bird species in real time\n",
    "\n",
    "I began the project by first searching for datasets online:\n",
    "* The Cornell Lab of Ornithology offers a free-to-use North America bird dataset, featuring 400 bird species and 48,000 photos with labels.\n",
    "* The California Institute of Technology offers a free-to-use *mainly* North America bird dataset, featuring 200 species and 6,033 images with bounding boxes and labels.\n",
    "\n",
    "However, starting this project in late Fall moving into Winter, I noticed there were only a handful of birds in my backyard. I began taking pictures and was able to identify the following 8 winter birds:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f279e8a",
   "metadata": {},
   "source": [
    "### Blue Jay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a20cbe",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/blue_jay.png\" alt=\"Blue Jay\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba8188",
   "metadata": {},
   "source": [
    "### Brown-headed Nuthatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47bbaa7",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/brown_headed_nuthatch.jpg\" alt=\"Brown-headed Nuthatch\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a2fb29",
   "metadata": {},
   "source": [
    "### Cardinal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea48606e",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/cardinal.jpg\" alt=\"Cardinal\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8acff8",
   "metadata": {},
   "source": [
    "### Carolina Chickadee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36642ef2",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/carolina_chickadee.jpg\" alt=\"Carolina Chickadee\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f4ba2f",
   "metadata": {},
   "source": [
    "### Carolina Wren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0621690",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/carolina_wren.jpg\" alt=\"Carolina Wren\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377f4ed2",
   "metadata": {},
   "source": [
    "### Downy Woodpecker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd65abd",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/downy_woodpecker.jpg\" alt=\"Downy Woodpecker\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fad8e66",
   "metadata": {},
   "source": [
    "### Red-bellied Woodpecker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6671afe",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/red_bellied_woodpecker.jpg\" alt=\"Red Bellied Woodpecker\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2875acd",
   "metadata": {},
   "source": [
    "### Tufted Titmouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb91150a",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/tufted_titmouse.jpg\" alt=\"Tufted Titmouse\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dc3060",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035fc778",
   "metadata": {},
   "source": [
    "These 8 birds were the only birds in my area, and some of these birds, such as the woodpeckers and the blue jays, are very rare to see. \n",
    "\n",
    "If only 8 birds are visiting the backyard, I realized that training the model on 400 bird species would create a more general model, but I rather limit the model to make its predictions of only the 8 birds that I know are present. \n",
    "\n",
    "Assuming a model that purely predicts classes randomly (i.e. no learning), the probability of guessing a bird correctly from 400 species is 0.25%, while the probability of guessing a bird correctly from 8 species is 12.5%.\n",
    "\n",
    "This means that I could simply use the Caltech and Cornell datasets and **only** select those 8 birds, but then I would only have between 18 and 180 pictures of each bird and I wanted to train this model with lots and lots of data.\n",
    "\n",
    "So, I decided to make this project a whole lot more difficult for me and to collect all of my data myself.\n",
    "\n",
    "In order to predict the species of a bird, I knew I needed to setup an environment outside that could attract birds as well as take photos of them in a consistent manner.\n",
    "\n",
    "With this intuition, I decided to build a bird feeder and mount a camera that is always streaming to my computer. The goal now was to create an algorithm that would detect objects (the object hopefully being a bird) and then save continous captures of that object to my local computer. I would then use those images to train a convolutionary neural network using FastAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acdc1fc",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4fd7c5",
   "metadata": {},
   "source": [
    "### Building the bird feeder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d03b8b",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/bird_feeder.gif\" alt=\"Bird Feeder\" width=\"600\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e348c8",
   "metadata": {},
   "source": [
    "First, I bought a simple platform bird feeder from a store. I then heavily modified it. As you can see in the animation above, the roof was lifted and the central support beam in pink was shifted to the back. I then found a waterproof box and mounted it to the back of the bird feeder. A webcam was then placed inside the bird feeder and I ran a 180ft cable from the bird feeder to my upstairs computer.\n",
    "\n",
    "A few notes about the bird feeder:\n",
    "Before implementing the webcam and cable solution, I originally was using a raspberry pi and camera module to wirelessly stream the video captures from the bird feeder to my computer. Although this solution was more compact, the frame rate drop from spotty network connectivity was horrible.\n",
    "\n",
    "This prompted me to switch to a wired solution. The webcam is a standard USB webcam and something I found interesting while building this is that USB 2.0 can only send data a lenth of 5 meters (16 ft) and USB 3.0 is actually slightly worse at 3 meters (10 ft). There is a solution though, it turns out you can send USB data over ethernet cables, and this is purely because the data wires inside of the cable are twisted at a precise angle and this drastically reduces interference and noise.\n",
    "\n",
    "With a Cat6 ethernet cable, you can send USB data up to 200ft and my computer is about 172 feet away from the bird feeder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab30a65",
   "metadata": {},
   "source": [
    "<table>\n",
    "   <tr>\n",
    "      <td><img src=\"demo_assets/side_view_feeder.jpg\" alt=\"Side View Bird Feeder\" width=\"600\"/></td>\n",
    "      <td><img src=\"demo_assets/feeder_angle_back_view.jpg\" alt=\"Back Angle View Bird Feeder\" width=\"600\"/></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f15cc87",
   "metadata": {},
   "source": [
    "So the images above show the final build. I know it's not pretty, and I was worried the birds were going to be scared of it, but thankfully they didn't seem to mind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8fa43e",
   "metadata": {},
   "source": [
    "### Capturing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed1c7b",
   "metadata": {},
   "source": [
    "You may be wondering why there is a large white wooden back drop behind the feeder, and that has everything to do with how my image capturing algorithm works.\n",
    "\n",
    "In order to capture images of birds, I need the webcam to be continuosly streaming footage to my computer. Whenever a bird comes to the feeder, I want the webcam to take a bunch of photos, but if no bird is present, I definitely don't want it to take photos. \n",
    "\n",
    "So how do I detect the precense of birds without building a machine learning model? And the answer is to simplify the problem. Instead of recognizing birds and taking photos, I need to simply recognize objects that were not present when the algorithm started. So if you compare the current frame of the webcam to the first frame of the webcam, you can take the difference and the result will provide some information. If there is no difference, there is no object. If there is a difference, there is likely an object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87805f35",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/diff_thresh_still.png\" alt=\"Difference and Thresholding - Still\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4decf16a",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/diff_thresh.gif\" alt=\"Difference and Thresholding - GIF\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e76847b",
   "metadata": {},
   "source": [
    "* On the upper left you see the raw footage, granted with some bounding boxes overlaid but that is actually drawn later.\n",
    "\n",
    "* On the upper right you see the grayscale footage, which is then, for lack of better words, subtracted from the first frame in grayscale.\n",
    "\n",
    "* The difference is displayed in the lower left and you can see for the most part is just looks like the ghost of a bird on a black background.\n",
    "\n",
    "* On the lower right you see the threshold frame, which is made from the difference frame and simply makes pixels above a certain threshold value pure white and everything else pure black."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37b0bd5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf2d4b",
   "metadata": {},
   "source": [
    "Now purely in an effort to save time, I'm not going to dive deep onto the object detection algorithm but in short:\n",
    "\n",
    "OpenCV makes it easy to work with something called a contour. A contour is an outline that represents the shape of something and it is mathematically different than an edge. \n",
    "\n",
    "So I apply OpenCV contour filtering to the threshold frame on the lower right, and when a certain amount of contours are found, I draw a bounding box that represents the max height and width of the contours found in a given frame, and that box is seen overlaid on the upper left frame.\n",
    "\n",
    "At this point the algorithm is quite trivial, if a bounding box exists- its because an object is in the frame, so start taking a bunch of photos and save them locally.\n",
    "\n",
    "When I first wrote this script I encountered a bunch of issues, mainly that the bird feeder is hung from a cable. So if any wind blows it even slightly, technically the current frame is different than the initial frame, so it will take photos. Furthermore, if a shadow appears on a tree in the background, it will take photos. \n",
    "\n",
    "After taking about 14,000 photos of nothingness, I placed the white board behind the bird feeder and reoriented the entire system so that the sun wouldn't cast shadows and this worked great. \n",
    "\n",
    "At this point I could now run the algorithm for hours at a time and it would capture photos of objects that entered the scene. \n",
    "\n",
    "Apart from a few squirrels, this system allowed me to collect over 60,000 images of birds, of which I used about 20,000 of."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01f98c5",
   "metadata": {},
   "source": [
    "### Verifying the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "757776a7",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "path = Path(os.getcwd())\n",
    "\n",
    "train_df = pd.read_csv(path/\"train_df.csv\")\n",
    "test_df = pd.read_csv(path/\"test_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f25afb",
   "metadata": {},
   "source": [
    "At this point, it's time to label my data. As mentioned earlier I have 8 classes and **20,398** usable images. Unfortunately there is no shortcut here, I manually labeled all of these photos by drag and dropping them into their corresponding folder.\n",
    "\n",
    "I also took photos from the Caltech and Cornell datasets, but this only added +60 images per bird species."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819a048e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b76d1b3",
   "metadata": {},
   "source": [
    "The first step here is to go through each folder (remember, each folder contains images related to that class) and create a legend that will inform FastAI of what images belong to what class.\n",
    "\n",
    "This is what that looks like. Each row is an entry. The column `fname` is the name of the photo, which happens to be the time the photo was captured. The column `rpath` is the relative path of where the photo is located and the column `label` is the photo's corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c01d813c",
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>fpath</th>\n",
       "      <th>rpath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-07--10-28-16-767.jpg</td>\n",
       "      <td>Blue Jay</td>\n",
       "      <td>C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-07--10-28-16-767.jpg</td>\n",
       "      <td>Blue Jay/2021-11-07--10-28-16-767.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-07--10-28-17-311.jpg</td>\n",
       "      <td>Blue Jay</td>\n",
       "      <td>C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-07--10-28-17-311.jpg</td>\n",
       "      <td>Blue Jay/2021-11-07--10-28-17-311.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-08--11-58-29-841.jpg</td>\n",
       "      <td>Blue Jay</td>\n",
       "      <td>C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-08--11-58-29-841.jpg</td>\n",
       "      <td>Blue Jay/2021-11-08--11-58-29-841.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-08--11-58-30-925.jpg</td>\n",
       "      <td>Blue Jay</td>\n",
       "      <td>C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-08--11-58-30-925.jpg</td>\n",
       "      <td>Blue Jay/2021-11-08--11-58-30-925.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-08--11-58-31-465.jpg</td>\n",
       "      <td>Blue Jay</td>\n",
       "      <td>C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-08--11-58-31-465.jpg</td>\n",
       "      <td>Blue Jay/2021-11-08--11-58-31-465.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          fname     label  \\\n",
       "0  2021-11-07--10-28-16-767.jpg  Blue Jay   \n",
       "1  2021-11-07--10-28-17-311.jpg  Blue Jay   \n",
       "2  2021-11-08--11-58-29-841.jpg  Blue Jay   \n",
       "3  2021-11-08--11-58-30-925.jpg  Blue Jay   \n",
       "4  2021-11-08--11-58-31-465.jpg  Blue Jay   \n",
       "\n",
       "                                                                                  fpath  \\\n",
       "0  C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-07--10-28-16-767.jpg   \n",
       "1  C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-07--10-28-17-311.jpg   \n",
       "2  C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-08--11-58-29-841.jpg   \n",
       "3  C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-08--11-58-30-925.jpg   \n",
       "4  C:\\Users\\micah\\rig-uni\\bird-ID-2\\data\\all_data\\Blue Jay\\2021-11-08--11-58-31-465.jpg   \n",
       "\n",
       "                                   rpath  \n",
       "0  Blue Jay/2021-11-07--10-28-16-767.jpg  \n",
       "1  Blue Jay/2021-11-07--10-28-17-311.jpg  \n",
       "2  Blue Jay/2021-11-08--11-58-29-841.jpg  \n",
       "3  Blue Jay/2021-11-08--11-58-30-925.jpg  \n",
       "4  Blue Jay/2021-11-08--11-58-31-465.jpg  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5745b9f0",
   "metadata": {},
   "source": [
    "**Class Distributions**\n",
    "\n",
    "| Index | Class                  | Count |\n",
    "|-------|------------------------|-------|\n",
    "| 0     | Blue Jay               | 92    |\n",
    "| 1     | Brown-headed Nuthatch  | 353   |\n",
    "| 2     | Cardinal               | 2519  |\n",
    "| 3     | Carolina Chickadee     | 14675 |\n",
    "| 4     | Carolina Wren          | 625   |\n",
    "| 5     | Downy Woodpecker       | 221   |\n",
    "| 6     | Red-bellied Woodpecker | 86    |\n",
    "| 7     | Tufted Titmouse        | 1827  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd703c31",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50abc423",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/class_distrubutions.png\" alt=\"Class Distributions\" width=\"600\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c788fd6",
   "metadata": {},
   "source": [
    "As you can see, the dataset is highly imbalanced.\n",
    "\n",
    "* **Blue Jay** accounts for **0.017%** of the total images.\n",
    "* **Brown-headed Nuthatch** accounts for **1.487%** of the total images.\n",
    "* **Cardinal** accounts for **12.499%** of the total images.\n",
    "* **Carolina Chickadee** accounts for **74.155%** of the total images.\n",
    "* **Carolina Wren** accounts for **2.702%** of the total images.\n",
    "* **Downy Woodpecker** accounts for **0.509%** of the total images.\n",
    "* **Tufted Titmouse** accounts for **8.632%** of the total images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3f59f6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a43e4",
   "metadata": {},
   "source": [
    "If I were to train the model right now, it's possible it would learn but it's much more likely that it would predict that a bird is a Carolina Chickadee 74% of the time, so the dataset will have to be over and under sampled. But first, we need to split the dataset into a train and test set. The validation set will be created from FastAI itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc2362",
   "metadata": {},
   "source": [
    "### Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4355440",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "def test_train_split(df, test_split_percent, label_helper):\n",
    "    frames = []\n",
    "    for i in range(len(label_helper)):\n",
    "        frames.append(df.groupby(['label']).get_group(label_helper[i][0]).reset_index())\n",
    "    test_frames = []\n",
    "    train_frames = []\n",
    "    for i in range(len(frames)):\n",
    "        dff = frames[i]\n",
    "        x = math.floor(dff.shape[0] * test_split_percent)\n",
    "        indices = np.random.choice(dff.index, x, replace=False)\n",
    "        test_frames.append(dff.iloc[indices].reset_index().drop(['level_0', 'index'], axis=1))\n",
    "        train_frames.append(dff.drop(indices).reset_index().drop(['level_0', 'index'], axis=1))\n",
    "    test_df = pd.concat(test_frames)\n",
    "    train_df = pd.concat(train_frames)\n",
    "    return test_df, train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a504041",
   "metadata": {},
   "source": [
    "First, I wrote a function to split the dataset. You can define a `test_split_percent`, which will simply randomly choose that percentage of images from each class and move them to a separate dataset. I chose 0.2, meaning 20 percent of each class will become the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ce3a826",
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>fpath</th>\n",
       "      <th>rpath</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blue Jay</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brown-headed Nuthatch</th>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardinal</th>\n",
       "      <td>503</td>\n",
       "      <td>503</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carolina Chickadee</th>\n",
       "      <td>2935</td>\n",
       "      <td>2935</td>\n",
       "      <td>2935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carolina Wren</th>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Downy Woodpecker</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red-bellied Woodpecker</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tufted Titmouse</th>\n",
       "      <td>365</td>\n",
       "      <td>365</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fname  fpath  rpath\n",
       "label                                      \n",
       "Blue Jay                   18     18     18\n",
       "Brown-headed Nuthatch      70     70     70\n",
       "Cardinal                  503    503    503\n",
       "Carolina Chickadee       2935   2935   2935\n",
       "Carolina Wren             131    131    131\n",
       "Downy Woodpecker           44     44     44\n",
       "Red-bellied Woodpecker     17     17     17\n",
       "Tufted Titmouse           365    365    365"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby(['label']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabfe4c4",
   "metadata": {},
   "source": [
    "Above is the test set, notice that there is still a data imbalance here but unlike in the training set, this is perfectly acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b3d450",
   "metadata": {},
   "source": [
    "### Over & Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "388d2cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "## Deletes 'remove_n' random rows\n",
    "def undersample(df, count, target):\n",
    "    remove_n = count - target\n",
    "    drop_indices = np.random.choice(df.index, remove_n, replace=False)\n",
    "    df_subset = df.drop(drop_indices)\n",
    "    return df_subset\n",
    "\n",
    "## Duplicates 'duplicate_n' random rows\n",
    "def oversample(df, count, target):\n",
    "    duplicate_n = math.ceil(target / count)\n",
    "    df_over = pd.concat([df]*duplicate_n)\n",
    "    over_count = df_over.shape[0]\n",
    "    if over_count > target:\n",
    "        remove_n = over_count - target\n",
    "        df_over = df_over.iloc[:-remove_n]\n",
    "    return df_over\n",
    "\n",
    "def over_under_sample(df, target, labels):\n",
    "    frames = []\n",
    "    for i, label in enumerate(labels):\n",
    "        dff = df[df.label == labels[i]].reset_index()\n",
    "        dff_count = dff.shape[0]\n",
    "        if dff_count > target:\n",
    "            dff = undersample(dff, dff_count, target)\n",
    "        elif dff_count < target:\n",
    "            dff = oversample(dff, dff_count, target)\n",
    "        dff.reset_index()\n",
    "        frames.append(dff)\n",
    "    balanced_df = pd.concat(frames)\n",
    "    return balanced_df.reset_index().drop(['level_0', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8178da7",
   "metadata": {},
   "source": [
    "Next, I wrote the dataset balancer. You can pass a number, `target`, and it will either oversample (randomly duplicate images) or undersample (randomly delete images) until each class has the exact same amount of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a7d8740",
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>fpath</th>\n",
       "      <th>rpath</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blue Jay</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brown-headed Nuthatch</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardinal</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carolina Chickadee</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carolina Wren</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Downy Woodpecker</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red-bellied Woodpecker</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tufted Titmouse</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fname  fpath  rpath\n",
       "label                                      \n",
       "Blue Jay                 1000   1000   1000\n",
       "Brown-headed Nuthatch    1000   1000   1000\n",
       "Cardinal                 1000   1000   1000\n",
       "Carolina Chickadee       1000   1000   1000\n",
       "Carolina Wren            1000   1000   1000\n",
       "Downy Woodpecker         1000   1000   1000\n",
       "Red-bellied Woodpecker   1000   1000   1000\n",
       "Tufted Titmouse          1000   1000   1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(['label']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435c9335",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/over_under_sample.png\" alt=\"Over Under Sample\" width=\"600\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b288afd2",
   "metadata": {},
   "source": [
    "After balancing the dataset, each class has 1000 samples and this is where we want to be. There is just one more thing we need to take care of before we can start training.\n",
    "\n",
    "The class `Carolina Chickadee` was undersampled, so over 13,000 images are not being used but the 1000 images that are being used are entirely unique. \n",
    "\n",
    "The class `Blue Jay` was oversampled. It only had 92 images to begin with and we pretty much duplicated images until there were 1000, so 908 images are not unique. If we trained the model with this, it could become overfit, so the solution is to do some data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c37f4b",
   "metadata": {},
   "source": [
    "### Data Augmentation and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d809bd",
   "metadata": {},
   "source": [
    "Below is a sample of one batch of data after performing some data augmentations and transforms using FastAI. \n",
    "\n",
    "Each image in a given class has a random probability of having one or multiple transformations applied to it, and these transformations are:\n",
    "* +- Contrast\n",
    "* +- Saturation\n",
    "* +- Brightness\n",
    "* +- Zoom\n",
    "* +- Rotated\n",
    "* +- Warped\n",
    "\n",
    "After these transformations, there are no unique images in any class. Every image that the network trains off of is different, even if the difference is slight.\n",
    "\n",
    "Additionally, all images are reszed to 240px by 320px, which is half their original resolution of 480px by 640px. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75bd449",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/one_batch.png\" alt=\"One Batch\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce19f22",
   "metadata": {},
   "source": [
    "Here you can see some of these images are rotated and zoomed in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976b9d35",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fec926",
   "metadata": {},
   "source": [
    "The position of the birds will generally be in the same spot, the bottom center, but this is not always the case. Blue jays and Red-bellied Woodpeckers are so large that they barely fit inside the frame, and Carolina Wrens often get really close to the camera and appear dark. All of the birds move horizontally and it's important that their relative location is not the identifying feature that the model learns.\n",
    "\n",
    "For most use cases, it is very important in image classification to use convolutional neural networks because they summarize all of the features seen in an image. This is in contrast to a traditional fully connected layer where the location of a feature is the actual input to the model, here a feature is the input.\n",
    "\n",
    "I trained 15 models total- the majority of these models were pretrained ResNet models, but a few were built using PyTorch's `nn.Sequential` class method. The model that performed the best was an implementation of ResNet50, so I will focus on that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9ac4f1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b06f04",
   "metadata": {},
   "source": [
    "This problem was solved using FastAI 2 and a pretrained convolution model called **ResNet50**.\n",
    "\n",
    "ResNet50 has 48 convolution layers, 1 maxpool and 1 average pool layer.\n",
    "\n",
    "The convolution layers create feature maps that *hopefully* identify features such as lines and edges. These maps, however, record the location of these features as well so the pooling layers are responsible for making it such that the position of a feature is irrelevant. \n",
    "\n",
    "ResNet50 was originally built for classifying animals into 1000 categories, so my belief is that the model already has the ability to recognize many different features such as colors and lines and angles. I can utilize transfer learning and retrain the model to work for my problem, which is classifying 8 species of birds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aa40ae",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/resnet50.jpg\" alt=\"Resnet50 Architecture\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255a4975",
   "metadata": {},
   "source": [
    "> https://stackoverflow.com/questions/54943307/create-cnn-model-architecture-diagram-in-keras\n",
    "\n",
    "> Optimized Deep Convolutional Neural Networks for Identification of Macular Diseases from Optical Coherence Tomography Images - Scientific Figure on ResearchGate. Available from: https://www.researchgate.net/figure/Left-ResNet50-architecture-Blocks-with-dotted-line-represents-modules-that-might-be_fig3_331364877 [accessed 27 Nov, 2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3b7e79",
   "metadata": {},
   "source": [
    "**Architecture**  \n",
    "ResNet50\n",
    "\n",
    "**Parameters**  \n",
    "Total parameters: 21,816,128\n",
    "\n",
    "**Hyperparameters**  \n",
    "Learning rate is determined using FastAI's `learner.lr_find()` class method, which helps find the learning rate whose slope has the greatest negative value. On average, this value was `10E-4.5`.   `24` epochs over 4 training cycles.\n",
    "\n",
    "**Loss Function**  \n",
    "ResNet50 uses `FlattenedLoss of CrossEntropyLoss` as its loss function. Cross-entropy calculates the different between two probability distributions, which is the output of the model.\n",
    "\n",
    "**Performance Metric**  \n",
    "I chose `Error Rate` as my metric, which is really just `1 - Accuracy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61607821",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5ada2f",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709e7c12",
   "metadata": {},
   "source": [
    "In the interest of saving time, I'm just going to quickly scroll through the training cycles. \n",
    "\n",
    "High level- there are 4 distinct training cycles using FastAI's `fit_one_cycle` and `fine_tune`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e94bd2",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "##### Training Cycle 1\n",
    "\n",
    "**Epochs: `5`**  \n",
    "**Alpha: `10E-2.5`**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bf83bb",
   "metadata": {},
   "source": [
    "<table>\n",
    "   <tr>\n",
    "      <td><img src=\"demo_assets/lrfind_1.png\" alt=\"LR Find 1\" width=\"600\"/></td>\n",
    "      <td><img src=\"demo_assets/lrresult_1.png\" alt=\"LR Result 1\" width=\"600\"/></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5864dd9c",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/cm_1.png\" alt=\"Confusion Matrix 1\" width=\"400\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebf6970",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "##### Training Cycle 2\n",
    "\n",
    "**Epochs: `8`**  \n",
    "**Alpha: `10E-3`**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e9c384",
   "metadata": {},
   "source": [
    "<table>\n",
    "   <tr>\n",
    "      <td><img src=\"demo_assets/lrresult_2.png\" alt=\"LR Result 2\" width=\"600\"/></td>\n",
    "      <td><img src=\"demo_assets/cm_2.png\" alt=\"Confusion Matrix 2\" width=\"600\"/></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7874e07",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "##### Training Cycle 3\n",
    "\n",
    "**Epochs: `3`**  \n",
    "**Alpha: `10E-6`**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3074c7e2",
   "metadata": {},
   "source": [
    "<table>\n",
    "   <tr>\n",
    "      <td><img src=\"demo_assets/lrfind_3.png\" alt=\"LR Find 3\" width=\"600\"/></td>\n",
    "      <td><img src=\"demo_assets/lrres_3.png\" alt=\"LR Result 3\" width=\"600\"/></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7909991e",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/cmatrix_3.png\" alt=\"Confusion Matrix 3\" width=\"400\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a0399d",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "##### Training Cycle 4\n",
    "\n",
    "**Epochs: `6`**  \n",
    "**Alpha: `10E-6.15`**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f449267c",
   "metadata": {},
   "source": [
    "<table>\n",
    "   <tr>\n",
    "      <td><img src=\"demo_assets/lrfind_4.png\" alt=\"LR Find 4\" width=\"600\"/></td>\n",
    "      <td><img src=\"demo_assets/lrres_4.png\" alt=\"LR Result 4\" width=\"600\"/></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab188e8",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/cm_4.png\" alt=\"Confusion Matrix 4\" width=\"400\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aa2d20",
   "metadata": {},
   "source": [
    "As you can see, by the fourth training cyle we have a `train_loss` of 0.027 and a `valid_loss` of 0.023. On our first training cycle `train_loss` was 0.81 and `valid_loss` was 0.69."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0704d48",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6993e6e",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/final_report.png\" alt=\"Final Report\" width=\"800\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b98bd5",
   "metadata": {},
   "source": [
    "**Precision:** ratio `tp / (tp + fp)`\n",
    "\n",
    "**Recall:** ratio `tp (tp + fn)`\n",
    "\n",
    "**F1-score:** weighted mean of precision and recall, 1 is best, 0 is worst.\n",
    "\n",
    "As you can see from the report generated from FastAI, the model has great results from the train and valid set. It appears that the Tufted Titmouse is our worse performer, but it still performed very well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f154b3c",
   "metadata": {},
   "source": [
    "### Making Predictions with the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76903ae1",
   "metadata": {},
   "source": [
    "To make sure the model is not overfit and to evaluate its performance before making live predictions, we must test the model by making predictions on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3305d50d",
   "metadata": {},
   "source": [
    "**Accuracy**: 96.72  \n",
    "**Score**: 1915/1980  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1454ca76",
   "metadata": {},
   "source": [
    "Out of 1980 images the model has not yet seen, it predicted 1915 of them correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c070bdb",
   "metadata": {},
   "source": [
    "### Live Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5c15b5",
   "metadata": {},
   "source": [
    "<table>\n",
    "   <tr>\n",
    "      <td><img src=\"demo_assets/pred2.png\" alt=\"Pred 2\" width=\"600\"/></td>\n",
    "      <td><img src=\"demo_assets/pred3.png\" alt=\"Pred 3\" width=\"600\"/></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0117a1",
   "metadata": {},
   "source": [
    "<table>\n",
    "   <tr>\n",
    "      <td><img src=\"demo_assets/pred4.png\" alt=\"Pred 4\" width=\"600\"/></td>\n",
    "      <td><img src=\"demo_assets/pred5.png\" alt=\"Pred 5\" width=\"600\"/></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bffec8d",
   "metadata": {},
   "source": [
    "<table>\n",
    "   <tr>\n",
    "      <td><img src=\"demo_assets/pred6.png\" alt=\"Pred 6\" width=\"600\"/></td>\n",
    "      <td><img src=\"demo_assets/pred7.png\" alt=\"Pred 7\" width=\"600\"/></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c534d760",
   "metadata": {},
   "source": [
    "<table>\n",
    "   <tr>\n",
    "      <td><img src=\"demo_assets/pred1.gif\" alt=\"Pred 1\" width=\"600\"/></td>\n",
    "      <td><img src=\"demo_assets/pred8.png\" alt=\"Pred 8\" width=\"600\"/></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bb97c0",
   "metadata": {},
   "source": [
    "Eventually, squirrels starting becoming aware of the bird feeder and became a problem. As you can see, the model is quite certain that this squirrel is a Tufted Titmouse, and honestly I can't blame it. Of the 8 birds it knows of, I too think that a squirrel looks most similar to a Tufted Titmouse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5540b5",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/sqi.gif\" alt=\"Squirrel Trouble\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b30b80",
   "metadata": {},
   "source": [
    "Due to squirrels using the white board to climb up to, I moved the bird feeder away from the board.It is encouraging to note that the model still performed well even when this familiar background was removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55a174d",
   "metadata": {},
   "source": [
    "<img src=\"demo_assets/sanity_check.gif\" alt=\"Sanity Check\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64ec985",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73862e21",
   "metadata": {},
   "source": [
    "To conclude, **BirdID** is a machine learning project used to predict the species of local birds in my backyard. The ML model was trained via transfer learning using the ResNet50 convolutional neural network with 8000 images of 8 local bird species collecting using object detection techniques.\n",
    "\n",
    "The model is set up to easily accommodate more classes as I collect more data.\n",
    "\n",
    "This was a difficult project, mainly because I chose to collect my own dataset, but I learned a lot about computer vision, machine learning, and birds in the process. I graduate in December and I plan to start working on BirdID version 2 in my free time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ca9e0c",
   "metadata": {},
   "source": [
    "# Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89d67a9",
   "metadata": {},
   "source": [
    "Any questions?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
